{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation System via a Gaussian Mixture Model for Matrix Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the entire model using only Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import our partially observed data matrix X along with the complete matrix which we will use as the ground truth to compare to later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('netflix_incomplete.txt')\n",
    "X_complete = np.loadtxt('netflix_complete.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we extract parameters from our matrix and initialize the mixture which is defined by mu (mean), p (weight), and var(variance). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "n, d = X.shape\n",
    "K = 12\n",
    "delta = np.where(X,0,1)\n",
    "\n",
    "#mixture\n",
    "np.random.seed(1)\n",
    "mu = X[np.random.choice(n,K, replace = False)]\n",
    "p = np.ones(K)/K\n",
    "var = np.sum((mu*np.ones([n,K,d]) - X.reshape([n,1,d]))**2, axis=(0,2))/(n*d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a function for computing the squared norm which depends only on the current mu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm(mu):\n",
    "    U = (mu*np.ones([n,K,d]))*delta.reshape([n,1,d])\n",
    "    sub_stack = U - X.reshape([n,1,d])\n",
    "    return np.sum(sub_stack**2, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function which runs the E-Step of the EM algorithm returning the soft counts (posterior) and the log-likelihood of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estep(X,mu,p,var):\n",
    "    \n",
    "    norm = compute_norm(mu)\n",
    "    \n",
    "    C_u = np.sum(delta,axis=1,keepdims=True)\n",
    "    logged_gauss = np.log(p) - C_u/2*np.log(2*np.pi*var*np.ones([n,K])) - norm/(2*var)\n",
    "    max_vector = np.amax(logged_gauss, axis=1, keepdims=True)\n",
    "    scaled_gauss = np.exp(logged_gauss - max_vector)\n",
    "    denom = max_vector + np.log(np.sum(scaled_gauss, axis=1, keepdims=True))\n",
    "    \n",
    "    log_post = logged_gauss - denom\n",
    "    log_likelihood = np.sum(denom)\n",
    "    \n",
    "    return np.exp(log_post), log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a function which runs the M-Step of the EM algorithm returning the updated mixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mstep(X, post, min_var, mu, p, var):\n",
    "    \n",
    "    norm = compute_norm(mu)\n",
    "    \n",
    "    #update mu\n",
    "    mu_numer = np.dot(X.T, post).T\n",
    "    mu_denom = np.dot(delta.T, post).T\n",
    "    mu = np.where(mu_denom >= 1, mu_numer/(mu_denom +1e-10), mu)\n",
    "    \n",
    "    #update var\n",
    "    C_u = np.sum(delta, axis=1, keepdims=True)\n",
    "    sum_factor = np.sum(post*norm, axis = 0)\n",
    "    first_factor = 1/np.sum(C_u*post, axis = 0)\n",
    "    var_bad = first_factor*sum_factor\n",
    "    var = np.where(var_bad < min_var, min_var, var_bad)\n",
    "    \n",
    "    #update p\n",
    "    p = np.sum(post, axis = 0)/n\n",
    "    \n",
    "    #update norm\n",
    "    norm = compute_norm(mu)\n",
    "    \n",
    "    return mu,p,var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function which runs the entire EM algorithm using our E-Step and M-Step functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "def run(X, mu, p ,var, min_var=.1):\n",
    "    \n",
    "    old_log = None\n",
    "    new_log = None\n",
    "    while old_log is None or (new_log - old_log > 1e-6*np.abs(new_log)):\n",
    "        old_log=new_log\n",
    "        \n",
    "        #E-step\n",
    "        post, new_log = estep(X, mu, p, var)\n",
    "        \n",
    "        #M-step\n",
    "        mu, p, var = mstep(X, post, min_var, mu, p, var)\n",
    "    \n",
    "    return mu,p,var,post,new_log\n",
    "        \n",
    "mu,p,var,post,old_log = run(X, mu, p, var, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the mixture to \"fill\" our incomplete matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(X,mu,p,var):\n",
    "    \n",
    "    post,_ = estep(X,mu,p,var)\n",
    "    X_pred = X.copy()\n",
    "    miss_indices = np.where(X == 0)\n",
    "    X_pred[miss_indices] = (post@mu)[miss_indices]\n",
    "    \n",
    "    return X_pred\n",
    "\n",
    "X_filled = fill(X,mu,p,var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we calculate the rmse between the complete and incomplete matrix. (It is important to know that the completed matrix was not used at all up to this point as in real world applications, we would not have access to that information.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.051719790109855"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rmse(X, Y):\n",
    "    return np.sqrt(np.mean((X - Y)**2))\n",
    "\n",
    "rmse(X_filled, X_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6787480867863673"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(X, X_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rmse score is much lower now as we had hoped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
